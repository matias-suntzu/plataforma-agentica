"""
API FastAPI con Memoria + Sistema de Feedback + Recommendations (V5)
âœ… Orchestrator V5 (4 agentes)
âœ… Contexto conversacional âœ…
âœ… Endpoints para guardar/listar feedback
âœ… VinculaciÃ³n con thread_id
"""

import os
import asyncio
import logging
import uuid
from datetime import datetime
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, Any, List

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from dotenv import load_dotenv

load_dotenv()

os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "meta-ads-agent"
os.environ["LANGSMITH_TRACING"] = "true"

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================================
# ESTADO GLOBAL
# ============================================
AGENT_READY = False
orchestrator_v5 = None

# ðŸ†• ALMACENAMIENTO EN MEMORIA PARA FEEDBACK
FEEDBACK_STORAGE: List[Dict[str, Any]] = []

# ðŸ†• ALMACENAMIENTO DE HISTORIAL DE MENSAJES POR THREAD
THREAD_MESSAGES: Dict[str, List[BaseMessage]] = {}


# ============================================
# SCHEMAS
# ============================================
class QueryRequest(BaseModel):
    query: str
    thread_id: Optional[str] = None
    user_id: str = "default"


class QueryResponse(BaseModel):
    response: str
    thread_id: str
    workflow_type: str
    metadata: Dict[str, Any] = {}
    timestamp: str


class FeedbackRequest(BaseModel):
    thread_id: str
    message_index: int
    rating: int
    comment: Optional[str] = None
    evaluator: Optional[str] = "user"
    agent_id: Optional[str] = "meta-ads-agent"


class FeedbackResponse(BaseModel):
    id: str
    thread_id: str
    message_index: int
    rating: int
    comment: Optional[str]
    evaluator: str
    agent_id: str
    status: str
    created_at: str


class UpdateFeedbackRequest(BaseModel):
    status: str


# ============================================
# FUNCIONES AUXILIARES PARA CONTEXTO
# ============================================

def get_thread_messages(thread_id: str) -> List[BaseMessage]:
    """Obtiene el historial de mensajes de un thread"""
    return THREAD_MESSAGES.get(thread_id, [])


def add_message_to_thread(thread_id: str, message: BaseMessage):
    """Agrega un mensaje al historial del thread"""
    if thread_id not in THREAD_MESSAGES:
        THREAD_MESSAGES[thread_id] = []
    THREAD_MESSAGES[thread_id].append(message)
    
    # Mantener solo Ãºltimos 20 mensajes para no saturar memoria
    if len(THREAD_MESSAGES[thread_id]) > 20:
        THREAD_MESSAGES[thread_id] = THREAD_MESSAGES[thread_id][-20:]


def clear_thread_messages(thread_id: str):
    """Limpia el historial de un thread"""
    if thread_id in THREAD_MESSAGES:
        del THREAD_MESSAGES[thread_id]


# ============================================
# INICIALIZACIÃ“N ASÃNCRONA
# ============================================
async def initialize_agent_background():
    global AGENT_READY, orchestrator_v5
    
    logger.info("â³ Iniciando carga asÃ­ncrona del agente V5...")
    
    try:
        from langgraph_agent.orchestration.orchestrator_v5 import OrchestratorV5
        
        logger.info("ðŸ“¦ MÃ³dulos importados")
        
        orchestrator_v5 = OrchestratorV5(enable_logging=True)
        
        AGENT_READY = True
        
        logger.info("âœ… Orchestrator V5 completamente inicializado (4 agentes)")
        logger.info("   - ConfigAgent âœ…")
        logger.info("   - PerformanceAgent âœ…")
        logger.info("   - RecommendationAgent âœ…")
        logger.info("   - Multi-Agent âœ…")
        logger.info("   - Contexto conversacional âœ…")
        
    except Exception as e:
        logger.error(f"âŒ Error crÃ­tico al inicializar agente: {e}")
        import traceback
        traceback.print_exc()


@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("ðŸš€ Servidor FastAPI iniciando...")
    asyncio.create_task(initialize_agent_background())
    yield
    logger.info("ðŸ›‘ Servidor cerrando...")


# ============================================
# APLICACIÃ“N FASTAPI
# ============================================
api = FastAPI(
    title="Meta Ads Agent API V5",
    description="Agente LangGraph con 4 agentes especializados + Contexto Conversacional + Sistema de Feedback",
    version="5.1-context",
    lifespan=lifespan
)

api.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================
# ENDPOINTS PRINCIPALES
# ============================================
@api.get("/health")
def health_check():
    """Health check que siempre responde rÃ¡pido"""
    checks = {
        "server": "running",
        "agent_ready": AGENT_READY,
        "orchestrator_v5": orchestrator_v5 is not None,
        "google_api": bool(os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")),
        "meta_api": bool(os.getenv("META_ACCESS_TOKEN")),
        "context_enabled": True,  # âœ… Nuevo
    }
    
    agents_available = 4 if AGENT_READY else 0
    
    status = "healthy" if True else "unhealthy"
    
    return {
        "status": status,
        "checks": checks,
        "version": "5.1-context",
        "agents_available": agents_available,
        "agent_types": [
            "ConfigAgent",
            "PerformanceAgent",
            "RecommendationAgent",
            "Multi-Agent"
        ] if AGENT_READY else [],
        "features": [
            "Conversational Context",  # âœ… Nuevo
            "Thread Memory",
            "Feedback System"
        ],
        "active_threads": len(THREAD_MESSAGES),  # âœ… Nuevo
        "feedback_count": len(FEEDBACK_STORAGE),
        "message": "Servidor operativo con contexto conversacional" if AGENT_READY else "Agente inicializando..."
    }


@api.post("/query", response_model=QueryResponse)
async def process_query(request: QueryRequest):
    """Procesar query con el agente V5 + contexto conversacional"""
    if not AGENT_READY or orchestrator_v5 is None:
        raise HTTPException(
            status_code=503, 
            detail="Agente aÃºn inicializando. Por favor espera 30 segundos y reintenta."
        )
    
    try:
        # Generar thread_id si no existe
        if not request.thread_id:
            thread_id = f"thread_{uuid.uuid4().hex[:12]}"
        else:
            thread_id = request.thread_id
        
        logger.info(f"ðŸ”¥ Query recibida - Thread: {thread_id}")
        logger.info(f"   Query: '{request.query[:100]}...'")
        
        # âœ… OBTENER HISTORIAL DE MENSAJES
        messages = get_thread_messages(thread_id)
        
        if messages:
            logger.info(f"   ðŸ“š Usando contexto: {len(messages)} mensajes previos")
        
        # âœ… PROCESAR CON CONTEXTO
        result = orchestrator_v5.process_query(
            query=request.query,
            thread_id=thread_id,
            messages=messages  # âœ… Pasar historial
        )
        
        # âœ… GUARDAR MENSAJES EN EL HISTORIAL
        add_message_to_thread(thread_id, HumanMessage(content=request.query))
        add_message_to_thread(thread_id, AIMessage(content=result.content))
        
        logger.info(f"âœ… Query procesada - Thread: {thread_id}")
        logger.info(f"   Workflow: {result.workflow_type}")
        logger.info(f"   Mensajes en thread: {len(THREAD_MESSAGES.get(thread_id, []))}")
        
        return QueryResponse(
            response=result.content,
            thread_id=thread_id,
            workflow_type=result.workflow_type,
            metadata=result.metadata or {},
            timestamp=datetime.utcnow().isoformat()
        )
    
    except Exception as e:
        logger.error(f"âŒ Error procesando query: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Error interno: {str(e)}")


# ============================================
# ðŸ†• ENDPOINTS DE FEEDBACK
# ============================================

@api.post("/feedback", response_model=FeedbackResponse)
async def submit_feedback(feedback: FeedbackRequest):
    """Guardar feedback de un mensaje especÃ­fico"""
    try:
        feedback_id = f"fb_{uuid.uuid4().hex[:12]}"
        
        feedback_data = {
            "id": feedback_id,
            "thread_id": feedback.thread_id,
            "message_index": feedback.message_index,
            "rating": feedback.rating,
            "comment": feedback.comment,
            "evaluator": feedback.evaluator,
            "agent_id": feedback.agent_id,
            "status": "pending",
            "created_at": datetime.utcnow().isoformat()
        }
        
        FEEDBACK_STORAGE.append(feedback_data)
        
        logger.info(
            f"âœ… Feedback guardado - ID: {feedback_id}, "
            f"Thread: {feedback.thread_id}, Rating: {feedback.rating}/10"
        )
        
        return FeedbackResponse(**feedback_data)
    
    except Exception as e:
        logger.error(f"âŒ Error guardando feedback: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api.get("/feedback")
async def list_feedback(
    thread_id: Optional[str] = None,
    agent_id: Optional[str] = None,
    limit: int = 100
):
    """Listar feedback con filtros opcionales"""
    try:
        filtered = FEEDBACK_STORAGE
        
        if thread_id:
            filtered = [f for f in filtered if f["thread_id"] == thread_id]
        
        if agent_id:
            filtered = [f for f in filtered if f["agent_id"] == agent_id]
        
        filtered = sorted(
            filtered,
            key=lambda x: x["created_at"],
            reverse=True
        )[:limit]
        
        if filtered:
            ratings = [f["rating"] for f in filtered]
            avg_rating = sum(ratings) / len(ratings)
            
            promoters = len([r for r in ratings if r >= 9])
            detractors = len([r for r in ratings if r <= 6])
            nps = ((promoters - detractors) / len(ratings)) * 100 if ratings else 0
        else:
            avg_rating = 0
            nps = 0
        
        return {
            "data": filtered,
            "total": len(filtered),
            "stats": {
                "avg_rating": round(avg_rating, 1),
                "nps_score": round(nps, 0),
                "total_feedback": len(FEEDBACK_STORAGE),
                "pending": len([f for f in FEEDBACK_STORAGE if f["status"] == "pending"]),
                "applied": len([f for f in FEEDBACK_STORAGE if f["status"] == "applied"])
            }
        }
    
    except Exception as e:
        logger.error(f"âŒ Error listando feedback: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api.get("/feedback/{feedback_id}")
async def get_feedback(feedback_id: str):
    """Obtener un feedback especÃ­fico por ID"""
    feedback = next((f for f in FEEDBACK_STORAGE if f["id"] == feedback_id), None)
    
    if not feedback:
        raise HTTPException(status_code=404, detail="Feedback no encontrado")
    
    return feedback


@api.put("/feedback/{feedback_id}")
async def update_feedback(feedback_id: str, update: UpdateFeedbackRequest):
    """Actualizar estado de un feedback"""
    try:
        feedback = next((f for f in FEEDBACK_STORAGE if f["id"] == feedback_id), None)
        
        if not feedback:
            raise HTTPException(status_code=404, detail="Feedback no encontrado")
        
        if update.status not in ["pending", "applied", "dismissed"]:
            raise HTTPException(status_code=400, detail="Estado invÃ¡lido")
        
        feedback["status"] = update.status
        feedback["updated_at"] = datetime.utcnow().isoformat()
        
        logger.info(f"âœ… Feedback {feedback_id} actualizado a: {update.status}")
        
        return feedback
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Error actualizando feedback: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api.delete("/feedback/{feedback_id}")
async def delete_feedback(feedback_id: str):
    """Eliminar un feedback"""
    global FEEDBACK_STORAGE
    
    feedback = next((f for f in FEEDBACK_STORAGE if f["id"] == feedback_id), None)
    
    if not feedback:
        raise HTTPException(status_code=404, detail="Feedback no encontrado")
    
    FEEDBACK_STORAGE = [f for f in FEEDBACK_STORAGE if f["id"] != feedback_id]
    
    logger.info(f"ðŸ—‘ï¸ Feedback {feedback_id} eliminado")
    
    return {"message": "Feedback eliminado", "id": feedback_id}

# ============================================
# Ã°Å¸â€ â€¢ ENDPOINTS DE MÃƒâ€°TRICAS Y DEBUG
# ============================================

@api.get("/metrics")
async def get_metrics():
    """Obtener mÃƒÂ©tricas del orchestrator"""
    if not AGENT_READY or orchestrator_v5 is None:
        raise HTTPException(status_code=503, detail="Agente no inicializado")
    
    try:
        metrics = orchestrator_v5.get_metrics()
        return {
            "metrics": metrics,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"Ã¢ÂÅ’ Error obteniendo mÃƒÂ©tricas: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api.get("/agents")
async def list_agents():
    """Listar agentes disponibles"""
    return {
        "agents": [
            {
                "name": "ConfigAgent",
                "description": "ConfiguraciÃƒÂ³n tÃƒÂ©cnica de campaÃƒÂ±as",
                "capabilities": [
                    "Listar campaÃƒÂ±as",
                    "Buscar campaÃƒÂ±as por nombre",
                    "Presupuestos",
                    "Estrategias de puja",
                    "Detalles de adsets"
                ]
            },
            {
                "name": "PerformanceAgent",
                "description": "MÃƒÂ©tricas de rendimiento",
                "capabilities": [
                    "Gasto real",
                    "Impresiones, clicks, CTR",
                    "CPM, CPC, CPA",
                    "Conversiones",
                    "TOP N anuncios",
                    "Comparaciones de perÃƒÂ­odos"
                ]
            },
            {
                "name": "RecommendationAgent",
                "description": "Recomendaciones de optimizaciÃƒÂ³n",
                "capabilities": [
                    "Detectar Advantage+ no activado",
                    "Identificar presupuestos bajos",
                    "Analizar targeting subÃƒÂ³ptimo",
                    "Sugerencias para reducir CPA/CPC"
                ]
            },
            {
                "name": "Multi-Agent",
                "description": "CombinaciÃƒÂ³n de mÃƒÂºltiples agentes",
                "capabilities": [
                    "AnÃƒÂ¡lisis completo de campaÃƒÂ±as",
                    "Reportes con config + rendimiento + recomendaciones"
                ]
            }
        ],
        "total_agents": 4,
        "agent_ready": AGENT_READY
    }


# ============================================
# OTROS ENDPOINTS
# ============================================
@api.post("/reset")
async def reset_conversation():
    """Crear nuevo thread_id para nueva conversaciÃƒÂ³n"""
    new_thread_id = f"thread_{uuid.uuid4().hex[:12]}"
    return {"thread_id": new_thread_id, "message": "Nueva conversaciÃƒÂ³n"}


@api.get("/")
async def root():
    """Root endpoint con informaciÃƒÂ³n del servicio"""
    return {
        "service": "Meta Ads Agent API V5",
        "version": "5.0-recommendations",
        "status": "operational" if AGENT_READY else "initializing",
        "agent_ready": AGENT_READY,
        "agents_count": 4,
        "endpoints": {
            "health": "/health (GET)",
            "query": "/query (POST)",
            "feedback": "/feedback (GET, POST)",
            "feedback_detail": "/feedback/{id} (GET, PUT, DELETE)",
            "metrics": "/metrics (GET)",
            "agents": "/agents (GET)",
            "reset": "/reset (POST)",
            "docs": "/docs",
            "status": "/status (GET)"
        }
    }


@api.get("/status")
async def status():
    """Status detallado del sistema"""
    return {
        "agent_ready": AGENT_READY,
        "orchestrator_v5_initialized": orchestrator_v5 is not None,
        "agents": {
            "config_agent": AGENT_READY,
            "performance_agent": AGENT_READY,
            "recommendation_agent": AGENT_READY,
            "multi_agent": AGENT_READY
        },
        "feedback_system": {
            "enabled": True,
            "total_feedback": len(FEEDBACK_STORAGE),
            "storage": "in-memory"
        },
        "environment": {
            "has_google_api": bool(os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")),
            "has_meta_api": bool(os.getenv("META_ACCESS_TOKEN")),
            "has_langsmith": bool(os.getenv("LANGCHAIN_API_KEY"))
        },
        "version": "5.0-recommendations"
    }

# ============================================
# ðŸ†• EXPOSICIÃ“N DE GRAPH PARA LANGGRAPH STUDIO
# ============================================

from langgraph.graph import StateGraph
from langchain_core.messages import BaseMessage
from typing import TypedDict

# Define el estado que manejarÃ¡ el graph
class AgentState(TypedDict):
    messages: List[BaseMessage]
    thread_id: str
    workflow_type: str
    metadata: Dict[str, Any]

# Crear el graph que LangGraph Studio puede entender
def create_graph():
    """Crear un graph LangGraph que encapsula el orchestrator"""
    graph = StateGraph(AgentState)
    
    def process_node(state: AgentState) -> AgentState:
        """Nodo que procesa la query usando el orchestrator"""
        if not AGENT_READY or orchestrator_v5 is None:
            return {
                **state,
                "messages": state["messages"] + [AIMessage(content="Agente inicializando...")]
            }
        
        # Obtener el Ãºltimo mensaje (query del usuario)
        if state["messages"]:
            last_message = state["messages"][-1]
            if isinstance(last_message, HumanMessage):
                query = last_message.content
                
                # Procesar con orchestrator
                result = orchestrator_v5.process_query(
                    query=query,
                    thread_id=state.get("thread_id", f"thread_{uuid.uuid4().hex[:12]}"),
                    messages=state["messages"][:-1]  # Historial sin el Ãºltimo mensaje
                )
                
                # Agregar respuesta
                response_message = AIMessage(content=result.content)
                
                return {
                    **state,
                    "messages": state["messages"] + [response_message],
                    "workflow_type": result.workflow_type,
                    "metadata": result.metadata or {}
                }
        
        return state
    
    graph.add_node("process", process_node)
    graph.set_entry_point("process")
    graph.set_finish_point("process")
    
    return graph.compile()

# Crear la instancia del graph
graph = create_graph()